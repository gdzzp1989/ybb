~~MQ：消息中间件
   1.异步解耦
   2.顺序消息
   3.流量削峰
   4.分布式事务
   5.大数据分析，日志分析
   6。分布式缓存


~~JAVA消息服务（JMS）：定义了java中访问消息中间件的接口
   通信模型：Point-to-Point（p2p）:点对点模型：队列中一个生产者发送的某个消息，只能被一个消费者所消费掉
             Publish/Subscribe：发布/订阅通信模型：在发布/订阅消息模型中，生产者发送的消息会被订阅了这个消息主题的所有消费者所消费
	                        该模式下，发布者与订阅者都是匿名的

   消息接收
	同步（Synchronous）：在同步消费信息模式模式中，订阅者/接收方通过调用 receive（）方法来接收消息。
			     在receive（long）方法中，线程会阻塞直到消息到达或者到指定时间后消息仍未到达。
　　	异步（Asynchronous）：使用异步方式接收消息的话，消息订阅者需注册一个消息监听者，类似于事件监听器，
			      只要消息到达，JMS服务提供者会通过调用监听器的onMessage()递送消息。

   接口
	管理对象（Administered objects）-连接工厂（Connection Factories）和目的地（Destination，就是queue）
	连接对象（Connections）
	会话（Sessions）
	消息（Message）
	消息生产者（Message Producers）
	消息消费者（Message Consumers）
	消息监听者（Message Listeners）


	/1.创建连接工场
        ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(url);
        //2.创建连接
        Connection connection = connectionFactory.createConnection();
        //3.启动连接
        connection.start();
        //4.创建会话
        Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
        //5.创建一个目标
        Destination destination = session.createTopic(queueName);
        //6.创建生产者or消费者


~~AMQP：一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准，和语言平台无关，大部分MQ都支持该协议
	AMQP协议中的元素包括：Message（消息体）、Producer（消息生产者）、Consumer（消息消费者）、Virtual Host（虚拟节点）、Exchange（交换机）、Queue（队列）等
	由Producer（消息生产者）和Consumer（消息消费者）构成了AMQP的客户端，他们是发送消息和接收消息的主体。AMQP服务端称为Broker，
		一个Broker中一定包含完整的Virtual Host（虚拟主机）、 Exchange（交换机）、Queue（队列）定义。
	一个Broker可以创建多个Virtual Host（虚拟主机），我们将讨论的Exchange和Queue都是虚拟机中的工作元素（还有User元素）。
		注意，如果AMQP是由多个Broker构成的集群提供服务，那么一个Virtual Host也可以由多个Broker共同构成。
	Connection是由Producer（消息生产者）和Consumer（消息消费者）创建的连接，连接到Broker物理节点上。但是有了Connection后客户端还不能和服务器通信，
		在Connection之上客户端会创建Channel，连接到Virtual Host或者Queue上，这样客户端才能向Exchange发送消息或者从Queue接受消息。
		一个Connection上允许存在多个Channel，只有Channel中能够发送/接受消息。
	Exchange元素是AMQP协议中的交换机，Exchange可以绑定多个Queue也可以同时绑定其他Exchange。消息通过Exchange时，
		会按照Exchange中设置的Routing（路由）规则，将消息发送到符合的Queue或者Exchange中。

~~ActiveMQ内置jetty容器

~~ActiveMQ事务：需要session.commit()

~~ActiveMQ的签收模式
	AUTO_ACKNOWLEDGE：自动签收
	CLIENT_ACKNOWLEDGE：调用acknowledge()签收消息，签收发生在Session层面：签收一个已经消费的消息会自动地签收这个Session所有已消费的收条。
	DUPS_OK_ACKNOWLEDGE：不必确保对传送消息的签收，这个模式可能会引起消息的重复，但是降低了Session的开销，所以只有客户端能容忍重复的消息，才可使用。

~~ActiveMQ消息重发机制（MessageListener的onMessage方法里抛出RuntimeException）
   参数：collisionAvoidanceFactor：碰撞躲避因数，默认值是0.15，和initialRedeliveryDelay配合设置拖延时间的范围
	 maximumRedeliveries ：最大重发次数，默认值是6
	 maximumRedeliveryDelay ：重发最大拖延时间，默认为-1
	 initialRedeliveryDelay ：第一次重发的拖延时间基础，默认是1000
	 redeliveryDelay ：如果initialRedeliveryDelay 为0，则使用redeliveryDelay ，默认也是1000
	 useCollisionAvoidance ：消息重发时是否采用前面提到的碰撞避免collisionAvoidanceFactor 参数，默认是false，不采用
	 useExponentialBackOff ：是否使用成倍增加拖延，默认为false，如果我们希望重发的拖延时间一次比一次大很多，则可以设置它为true
	 backOffMultiplier ：成倍拖延时间的倍率，默认为5
 
~~ActiveMQ消息传送模式
	PERSISTENT：默认为持久消息
	NON_PERSISTENT：可以容忍消息丢失，使用非持久化模式可以改善性能和减小存储开销。

	也可以使用priority设置消息优先级

~~ActiveMQ的消费消息选择和mysql持久化

~~ActiveMQ使用createTemporaryQueue，CreateTemporaryTopic创建临时队列实现request/reply模型

~~zookeeper实现activemq的主从环境搭建

~~ActiveMQ结合Master-Slave模式和Broker-Cluster模式（各个broker通过网络互相连接，并共享queue）实现负载均衡高可用


~~kafka
   消费者：（Consumer）：从消息队列中请求消息的客户端应用程序
   生产者：（Producer） ：向broker发布消息的应用程序
   AMQP服务端（broker）：用来接收生产者发送的消息并将这些消息路由给服务器中的队列，便于fafka将生产者发送的消息，
                         动态的添加到磁盘并给每一条消息一个偏移量，所以对于Kafka一个broker就是一个应用程序的实例
   主题（Topic）：一个主题类似新闻中的体育、娱乐、教育等分类概念，在实际工程中通常一个业务一个主题。
   分区（Partition）：一个Topic中的消息数据按照多个分区组织，分区是Kafka消息队列组织的最小单位，由创建Topic时指定Partition的数量


~~zookeeper实现kafka集群模式安装
   1.Broker注册到zk：每个broker启动时，都会注册到zk中，把自身的broker.id通知给zk。待zk创建此节点后，
		     kafka会把这个broker的主机名和端口号记录到此节点。
   2.Topic注册到zk：当broker启动时，会到对应topic节点下注册自己的broker.id到对应分区的isr列表中；
		    当broker退出时，zk会自动更新其对应的topic分区的ISR列表，并决定是否需要做消费者的rebalance
   3.Consumer注册到zk：一旦有新的消费者组注册到zk，zk会创建专用的节点来保存相关信息。如果zk发现消费者增加或减少，会自动触发消费者的负载均衡。


~~kafka副本（Replication）:Kafka每个topic的partition可以有N个副本，其中N是topic的复制因子。Kafka通过多副本机制实现故障自动转移
            N个副本中。其中一个partition为leader，其他都为follower（replication），leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。 leader会去维护ISR(副本同步队列)的列表
	    在集群环境中，一个topic下的多个partition会被分配到不同的broker上，partition的replication也在不同的broker上

~~kafka创建副本的2种模式
   同步复制
	producer联系zk识别leader；
	向leader发送消息；
	leader收到消息写入到本地log(ISR)；
	follower从leader pull消息；
	follower向本地写入log；
	follower向leader发送ack消息；
	leader收到所有follower的ack消息
   异步复制
	leader写入本地log之后，直接向client回传ack消息，不需要等待所有follower复制完成

~~kafka集群leader选举
   在kafka集群中，第一个启动的broker会在zk中创建一个临时节点/controller让自己成为控制器。
   其他broker启动时也会试着创建这个节点当然他们会失败，因为已经有人创建过了。那么这些节点会在控制器节点上创建zk watch对象，这样他们就可以收到这个节点变更的通知。
   任何时刻都确保集群中只有一个leader的存在。如果别的broker离开了集群，那么leader会去确定离开的broker的分区并确认新的分区领导者(即分区副本列表里的下一个副本)。
   然后向所有包含该副本的follower或者observer发送请求。随后新的分区首领开始处理请求。


~~kafka发消息方式
   发送并忘记(fire-and-forget)：我们把消息发送给服务器，但井不关心它是否正常到达。大多数情况下，消息会正常到达，因为Kafka 是高可用的，而且生产者会自动尝试重发。不过，使用这种方式有时候也会丢失一些消息。
   同步发送：使用send()方怯发送消息， 它会返回一个Future对象，调用get()方法进行等待，就可以知道消息是否发送成功。
   异步发送：调用send()方法并且指定一个回调函数，服务器在返回响应时调用该函数

~~kafka消费者群组
    每个消费者必须是属于某个消费者群组。一个群组里的消费者订阅的是同一个主题，如果一个群组中的多个消费者订阅了同一个分区，那么只能有一个消费者可以同时获得这一条消息

~~kafka独立消费者：不需要订阅主题，而是为自己分配分区，如果主题增加了新的分区，消费者并不会收到通知。所以，要么周期性地调用consumer.partitionsFor()方法来检查是否有新分区加入，要么在添加新分区后重启应用程序。


~~kafka消息偏移量：因为kafka服务端不保存消息的状态，所以消费端需要自己去做很多事情。我们每次调用poll()方法他总是返回已经保存在生产者队列中还未被消费者消费的消息。
                   消息在每一个分区中都是顺序的，那么必然可以通过一个偏移量去确定每一条消息的位置
    位移管理(offset management)
       自动提交：默认的5s提交时间
       手动提交：阻塞
       异步手动提交：非阻塞
       同步和异步组合提交
    群组内消费者有变动会触发再均衡的问题解决

~~kafka消息处理机制
   每当用户往某个Topic发送数据时，数据会被hash到不同的partition,这些partition位于不同的集群节点上


~~kafka API
    High Level Consumer API：将底层具体获取数据、更新offset、设置偏移量等操作屏蔽掉，直接将操作数据流的处理工作提供给编写程序的人员。优点是：操作简单；缺点：可操作性太差，无法按照自己的业务场景选择处理方式
                             可用多线程处理，线程数量大于Partition数量，那么有些线程收不到消息，线程数量小于Partition数量，那么线程收到多个Partition的消息，就无法保持收到消息的顺序（一个Partition的消息时有序的）

    Lower Level Consumer API：Simple Consumer API


~~Zookeeper+Kafka+Storm+HDFS:
   消息通过各种方式进入到Kafka消息中间件，比如可以通过使用Flume来收集日志数据，然后在Kafka中路由暂存，然后再由实时计算程序Storm做实时分析，最后将结果保存在HDFS中，
   这时我们就需要将在Storm的Spout中读取Kafka中的消息，然后交由具体的Spot组件去分析处理

~~kafka 吞吐量高的原因
   顺序读写：kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
   零拷贝：跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”
   分区：kafka中的topic中的内容可以被分为多分partition存在,每个partition又分为多个段segment,所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力
   批量发送和数据压缩：Producer可以通过GZIP或Snappy格式对消息集合进行压缩

~~ELK：是三个开源软件的缩写,分别表示:Elasticsearch , Logstash, Kibana
       一般配置
           filebeat(按照在服务器上的采集工具，发送数据到kafka)
	   filebeat                             --->Logstash(数据进行分析)--->Elasticsearch(数据存储)--->Kibana(数据页面展示)                        
	   filebeat

       分布式部署结构
        filebeat(按照在服务器上的采集工具，发送数据到kafka)
	filebeat --->kafka(消息队列服务)                        
	filebeat

        logstash			Elasticsearch（data）
        logstash取kafka的数据进行分析-->Elasticsearch（master）->Kibana
	logstash			Elasticsearch（client）


~~RabbitMQ高可用集群部署
    普通模式：节点只有相同的元数据，即队列结构结构，取消息时节点之间临时通信取数据给客户端
    镜像模式：把需要的队列做成镜像队列，消息实体会主动在镜像节点间同步，属于 RabbitMQ 的 HA 方案

~~RabbitMQ内存节点：只保存状态到内存（一个例外的情况是：持久的 queue 的持久内容将被保存到 disk）；
   RabbitMQ磁盘节点：保存状态到内存和磁盘，内存节点虽然不写入磁盘，但是它执行比磁盘节点要好，集群中，只需要一个磁盘节点来保存状态 就足够了


~~RabbitMQ：基于AMQP协议，消息（message）被发布者（publisher）发送给交换机（exchange），
	     然后交换机将收到的消息根据路由规则分发给绑定的队列（queue）。
	     最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。
    
~~RabbitMQ工作流程介绍
	1.建立信息。Publisher定义需要发送消息的结构和内容。
	2.建立Conection和Channel。由Publisher和Consumer创建连接，连接到Broker的物理节点上，同时建立Channel。
		Channel是建立在Connection之上的，一个Connection可以建立多个Channel。Publisher连接Virtual Host(虚拟主机) 建立Channel，
		Consumer连接到相应的Queue上建立Channel。
	3.声明交换机和队列。声明一个消息交换机（Exchange）和队列（Queue），并设置相关属性。
	4.发送消息。由Publisher发送消息到Broker中的Exchange中
	5.路由转发。RabbitMQ收到消息后，根据消息指定的Exchange(交换机)来查找Queue的Binding key(绑定)然后根据规则（Routing Key）分发到不同的Queue。
		这里就是说使用Routing Key在消息交换机（Exchange）和消息队列（Queue）中建立好绑定关系，然后将消息发送到绑定的队列中去。
	6.消息接收。Consumer监听相应的Queue，一旦Queue中有可以消费的消息，Queue就将消息发送给Consumer端。
	7.消息确认。当Consumer完成某一条消息的处理之后，需要发送一条ACK消息给对应的Queue。
	8.关闭消息通道（channel）以及和服务器的连接。

~~RabbitMQ中的交换机Exchange（注意这套规则不是AMQP协议规范提供的）
   Direct Exchange（直连交换机）：把消息投递给routing_key完全匹配的队列
   Fanout Exchange（扇型交换机）：将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。采用广播机制传递消息。
   Topic Exchange（主题交换机）：通过使用带规则的routing_key来对实现对消费分配到队列中，
			*（星号）：可以（只能）匹配一个单词
			#（井号）：可以匹配多个单词（或者零个）
   Headers Exchange（头交换机）：生产者发送一个含有消息头（key-value）的消息，消费者添加”x-match:any”或”x-match:all”参数，和键值来匹配消息头的键值。
  
~~RabbitMQ消息分发机制
   轮询分发:RabbitMQ会逐个发送消息到在序列中的下一个消费者(而不考虑每个任务的时长等等，且是提前一次性分配，并非一个一个分配)。平均每个消费者获得相同数量的消息
   公平分发：根据消费者的处理能力来进行分发处理的。这里主要是通过设置prefetchCount 参数来实现的。这样RabbitMQ就会使得每个Consumer在同一个时间点最多处理规定的数量级个数的Message，
             使用此模式必须关闭自动应答，改为手动应答

~~RabbitMQ消息确认机制(生产者)
   1.通过AMQP事务机制实现（需要关闭channel的confirm模式,设置成transaction模式）
      java代码实现channel.txSelect()->channel.txCommit()->channel.txRollback()
      SpringBoot使用RabbitTemplate开始同步/异步事务(同步支持XA事务)
      消费者设置autoAck=false手动应对支持事务
   2.通过将channel设置成confirm模式来实现（channel.confirmSelect()开启）（推荐）
      普通Confirm模式：每发送一条消息（channel.basicPublish发送消息）后，调用channel.waitForConfirms()方法，等待服务器端Confirm。实际上是一种串行Confirm了，
		       每publish一条消息之后就等待服务端Confirm，如果服务端返回false或者超时时间内未返回，客户端进行消息重传；
      批量Confirm模式：批量Confirm模式，每发送一批消息之后，调用channel.waitForConfirms()或channel.waitForConfirmsOrDie()（等到最后一条消息才执行，阻塞）方法，等待服务端Confirm，这种批量确认的模式极大的提高了Confirm效率，
                       但是如果一旦出现Confirm返回false或者超时的情况，客户端需要将这一批次的消息全部重发，这会带来明显的重复消息，
	               如果这种情况频繁发生的话，效率也会不升反降；
      异步Confirm模式：提供一个回调方法channel.addConfirmListener()，服务端Confirm了一条或者多条消息后Client端会回调这个方法。
      
      Spring Boot使用Producer的Confirm模式：rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback(){...});
     
~~RabbitMQ消息确认机制(消费者):Confirm模式
      消费者在声明队列时，可以指定noAck参数，当noAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息。
      否则，RabbitMQ会在队列中消息被消费后立即删除它
   手动确认（Spring Boot配置spring.rabbitmq.listener.acknowledge-mode=manual）
     basic.ack: 用于肯定确认，multiple参数用于多个消息确认。 channel.basicAck(envelope.getDeliveryTag(), false);
     basic.recover：是路由不成功的消息可以使用recovery重新发送到队列中。 
     basic.reject：是接收端告诉服务器这个消息我拒绝接收,不处理,可以设置是否放回到队列中还是丢掉，
                   而且只能一次拒绝一个消息,官网中有明确说明不能批量拒绝消息，为解决批量拒绝消息才有了basicNack。 
     basic.nack：可以一次拒绝N条消息
   自动确认：消息在发送后立即被认为是发送成功。 这种模式可以提高吞吐量


~~RabbitMQ消息重复投递或重复消费
   在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id(messageId)，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；
   在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费。


~~RabbitMQ消息持久化：将交换器/队列的durable属性设置为true，表示交换器/队列是持久交换器

~~RabbitMQ中的用户角色及其权限
   超级管理员（administrator）
   监控者（monitor）
   决策制定者（policymaker）
   普通管理者（management）
   其他（none）

~~RabbitMQ设置vhost，指定用户只能访问该虚拟机下的队列和交换机