~~java大文本读取：
  1.文件字节流，java.io.BufferedInputStream，每次读取固定长度到数组中
  2.使用通道和缓冲，java.nio.channels.FileChannel，java.nio.ByteBuffer，数据到缓冲区再到数组
  3.MappedByteBuffer类使用内存映射来读取数据
  4.RandomAccessFile类读取任意位置的数据，可采用多线程读取不同位置的数据
   linux sed 替换字符串

  内存映射：把文件的内容被映像到计算机虚拟内存的一块区域，从而可以直接操作内存当中的数据而无需每次都通过 I/O 去物理硬盘读取文件。这是由当前 java 态进入到操作系统内核态，由操作系统读取文件，
            再返回数据到当前 java 态的过程。这样就能大幅提高我们操作大文件的速度

~~大量数据去重
   bitmap（位图法）:照集合中最大元素max创建一个长度为max+1的新数组，然后再次扫描原数组，遇到几就给新数组的第几位置上（jdk实现类BitSet）
   布隆过滤器：Guava包，可指定误判率，使用多个hash算法得到多个hash值，在对应多个位置上置1
     特点：多个hash，增大随机性，减少hash碰撞的概率
           扩大数组范围，使hash值均匀分布，进一步减少hash碰撞的概率。

~~强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值
  弱一致性：系统并不保证续进程或者线程的访问都会返回最新的更新过的值。
  最终一致性：弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值

~~接口调用超时方案解决
   1.增加超时时间
   2.尝试多调用一次
   3.使用待处理队列处理
   4.回滚数据，重新调用
   5.异步机制


~~分布式如何保证事务一致性
  基本理念
  1.两阶段提交协议(2PC):
      准备阶段：事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务
      提交阶段：如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源
      问题：同步阻塞，还是有可能数据不一致
  2.三阶段提交协议(3PC):三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段分成了两步: 询问状态，然后再预提交，最后真正提交
       问题：还是有可能数据不一致
  3.Paxos算法

  常用实现:
   1.JTA：java平台上事务规范JTA，基于XA架构上建模,tomcat需要Automikos第三方框架实现
          XA协议:指的是TM（事务管理器）和 RM（资源管理器）之间的接口。目前主流的关系型数据库产品都是实现了 XA 接口，采用两阶段提交方式来管理分布式事务
     实现难度不算太高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况
   2.本地消息表(ebay模式):将远程分布式事务拆分成一系列的本地事务,借助关系型数据库新建消息表记录状态
     避免了分布式事务,会给数据库造成压力
   3.TCC框架：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作
     多写很多补偿的代码
   4.MQ事务消息：使用MQ发送消息，第一阶段Prepared消息，会拿到消息的地址。第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。
     主流的开源 MQ（ActiveMQ、RabbitMQ、Kafka）均未实现对事务消息的支持，所以需二次开发
   4.Saga模式:把分布式系统中的长事务为多个短事务，然后由Sagas工作流引擎负责协调。
   5.阿里的分布式事务处理方案 GTS
   6.LCN:对本地事务的协调控制，框架本身并不创建事务，只是对本地事务做协调控制(@TxTransaction(isStart=true))
  


~~分布式Session一致性问题
   session同步法：多台web-server相互同步数据
   客户端存储法：一个用户只存储自己的数据
   反向代理hash一致性：四层hash和七层hash都可以做，保证一个用户的请求落在一台web-server上
   后端统一存储：web-server重启和扩容，session也不会丢失

~~JWT（JSON Web Token）:解决跨域身份验证的问题，当用户与服务器通信时，服务器在请求中发回JSON对象。
      服务器仅依赖于这个JSON对象来标识用户。为了防止用户篡改数据，服务器将在生成对象时添加签名

      JWT的数据结构：JWT头(签名使用的算法)、有效载荷（主体内容部分，也是一个JSON对象）和签名



~~分布式系统权限认证
   1.TTP BASIC AUTH：每次请求API的时候，都会把用户名和密码通过restful API传给服务端
   2.Session和cookie：服务端全局创建session对象，session对象保存着各种关键信息，同时向客户端发送一组sessionId，成为一个cookie对象保存在浏览器中，会有跨域问题
   3.Token认证：类似JWT，服务端验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端，客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里
   4.JWT

~~分布式锁
  Mysql实现分布式锁
    建表
      利用索引唯一性实现锁:可重入可自旋
      用for update 排他锁
      加version字段实现 乐观锁
  Redis实现分布式锁
      利用SETNX，GETSET等命令可以实现悲观锁，乐观锁(问题：阻塞，集群模式可能锁丢失)
      进阶：使用实现redlock算法的redisson，Redisson是一个在Redis的基础上实现的Java驻内存数据网格
            基于redlock算法，根据lua 脚本和watch dog机制实现了自动延期，可重入 ，还可实现读写锁、公平锁，联锁等等
  ZooKeeper分布式锁实现：
      创建一个目录mylock，利用创建节点的序号和消息广播实现锁

~~分布式任务协调

 quartz集群部署：需数据库见表实现


~~分布式配置中心


~~限流算法
   计数器算法：我们会限制一秒钟的能够通过的请求数，比如限流qps为100，就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，
	    那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。通过 AtomicLong#incrementAndGet()方法来给计数器加1并返回最新值
	    ，通过这个最新值和阈值进行比较。这种实现方式有一个弊端：如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为"突刺现象"
   漏桶算法：为了消除"突刺现象"，可以采用漏桶算法实现限流，算法内部有一个容器，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。通过漏桶算法进行限流，
	     每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里
	     在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。
	     这种算法的弊端是无法应对短时间的突发流量。
   令牌桶算法：根据限流大小，设置按照一定的速率往桶里添加令牌，所有的请求在处理之前都需要拿到一个可用的令牌才会被处理.
           具体实现：1.通过Google开源的guava包，通过RateLimiter类的create方法，创建一个令牌桶算法的限流器
		     2.Java自带delayqueue的延迟队列实现
		     3.redis+lua脚本 实现分布式令牌桶，存储两个key，一个用于计时，一个用于计数。请求每调用一次，计数器增加1，若在计时器时间内计数器未超过阈值，则可以处理任务 
   滑动窗口算法：为每个调用方维护一个长度为limit的先进先出队列， 将每次请求的时间戳放到队列中， 比如阈值是10次/1s 那么limit = 10, 每次请求时取出队列头部(下标为limit -1 )的时间戳timestamp1，
	         假如timestamp1存在并且本次请求的时间戳减去timestamp1小于等于时间窗口长度expiry(单位为秒, 时间戳的单位也是秒)， 比如阈值是10次/1s， 
	         那么expiry=1， 那么说明在一个时间窗口长度内请求数量超过了阈值需要限流。否则就把这次请求的时间戳放入队列中， 并更新队列过期时间。
                 缺点是限流10万次/小时那么就需要维护一个长度为10万的队列，占用的内存大

~~应用限流
   1.Tomcat配置配置最大连接数，自定义线程池等
   2.guava的RateLimiter进行service层切面限流，基于令牌桶算法
   3.Nginx的限流模块
   4.OpenResty

   测试方法：linux下的ab（apachebench）压测，ab命令



~~数据库分库分表的问题
   1.事务一致性
   2.跨节点的关联查询join问题
	解决：ER分片
	      myCat数据组装

   3.跨节点的分页，排序，函数问题

   4.全局主键
     解决：UUID
	   SnowFlake 雪花算法
           基于数据库的主键

   5.数据迁移和扩容



~~服务器推送技术
  1.SSE(Server Send Event)：前端js使用EventSource,SpringMvc输出的媒体类型为text/event-stream,需要新式游览器支持
  2.Servlet 3.0+异步方法：前端递归ajax请求，后端SpingMvc开启异步方法支持setAsyncSupported(true)
  3.WebSocket
 

 ~~MySQL中SELECT+UPDATE处理并发更新问题解决方案
  1.利用一条比较复杂的SQL解决问题，不利于维护，因为把具体业务糅在SQL里了，以后修改业务时不但需要读懂这条SQL，还很有可能会修改成更复杂的SQL
  2.写独占锁，可以解决问题，但不常用
  3.加乐观锁


~~BASE64加密中文过程
   1.根据中文的编码转化成10进制
   2.10进制转2进制
   3.已6个为一组分组，不足6个后面补0(6位为64)
   6.再转10进制，根据BASE64的编码转为BASE64的编码


~~不使用第三个变量来交换两个数的值
   1.  int a=10,b=12;
       a=b-a; //a=2;b=12
       b=b-a; //a=2;b=10
       a=b+a; //a=10;b=10
   2. int a=10,b=12; //a=1010 b=1100
      a=a^b; //a=1010^1100=0110;
      b=a^b; //b=0110^1100=1010;
      a=a^b; //a=0110^1010=1100;


~~使用两个栈实现一个队列
   我们都知道栈是先进后出的结构，而队列是先进先出的结构。要实现一个队列的功能我们用栈s1来实现入队列的操作，栈s2来实现出队列的操作。
   入队列的操作和入栈一样，将数据保存到s1中即可。出队列时，我们首先判断一下栈s2是否为空，若为空，则将栈s1中的数据从栈顶元素开始依次入栈s2
   ，并删除s1栈顶元素，这样s1栈底元素就到了s2的栈顶，然后删除s2栈顶元素。若不为空，则直接将s2栈顶元素删除。这样就能实现队列的先进先出的特点

~~使用两个队列实现一个栈
   使用两个队列实现一个栈，入栈的操作和入队列的操作一样，将数据保存到队列q1中即可。出栈时，将除队尾元素以外的所有元素都入到队列q2中，并在队列q1中删除。
   然后将队列q1中队尾元素删除，再将q2中元素依次入队列q1。这样就将队列q1中的队尾元素删除，即是实现了栈的后进先出特点。